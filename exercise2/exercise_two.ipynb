{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBovZiB-Czqu",
        "outputId": "f17b40a3-abcd-469c-ea4d-b61157bd2af6"
      },
      "outputs": [],
      "source": [
        "!pip install rawpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs2sklbP0Nyf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import rawpy\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNZHmoWHfkzA",
        "outputId": "59f7bc93-aef0-4624-ef34-d7dc0dafc3d3"
      },
      "outputs": [],
      "source": [
        "raw_data = np.load('/content/drive/MyDrive/Colab Notebooks/Exercise 2/IMG_9939.npy')\n",
        "print(raw_data)\n",
        "print(raw_data.min())\n",
        "print(raw_data.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL1J9WqtfSlm"
      },
      "source": [
        "# **Exercise One**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "CdfrN5miLmJB",
        "outputId": "026d6212-bc41-42f1-879d-bbfb18081093"
      },
      "outputs": [],
      "source": [
        "slice_of_raw_data = raw_data[0:10, 0:10]\n",
        "print(slice_of_raw_data)\n",
        "plt.imshow(slice_of_raw_data)\n",
        "plt.title('Slice of Raw Data')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXFfjyzdOXgL",
        "outputId": "dda24c06-3d39-4d9f-b3a5-c865056cd217"
      },
      "outputs": [],
      "source": [
        "green_channel_1 = slice_of_raw_data[0::2, 0::2]\n",
        "green_channel_2 = slice_of_raw_data[1::2, 1::2]\n",
        "print(green_channel_1)\n",
        "print(\" \")\n",
        "print(green_channel_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_BoBL1WSGUL",
        "outputId": "7d7b60e1-4d92-48f6-c653-da31effebedf"
      },
      "outputs": [],
      "source": [
        "red_channel = slice_of_raw_data[1::2, 0::2]\n",
        "print(red_channel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZE2SE49TEGc",
        "outputId": "91958feb-b283-4ae8-af68-9747e5c11496"
      },
      "outputs": [],
      "source": [
        "# Blue channel will be at odd rows and odd columns\n",
        "blue_channel = slice_of_raw_data[0::2, 1::2]\n",
        "blue_channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU7Rl3uHfYwl"
      },
      "outputs": [],
      "source": [
        "green_channel_1 = raw_data[0::2, 0::2]\n",
        "green_channel_2 = raw_data[1::2, 1::2]\n",
        "red_channel = raw_data[1::2, 0::2]\n",
        "blue_channel = raw_data[0::2, 1::2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZESEPl9YgBoc"
      },
      "source": [
        "# **Exercise Two**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mipd48F9lN-g"
      },
      "outputs": [],
      "source": [
        "# File paths\n",
        "file_3044 = '/content/drive/MyDrive/Colab Notebooks/Exercise 2/IMG_3044.CR3'\n",
        "file_3045 = '/content/drive/MyDrive/Colab Notebooks/Exercise 2/IMG_3045.CR3'\n",
        "file_3046 = '/content/drive/MyDrive/Colab Notebooks/Exercise 2/IMG_3046.CR3'\n",
        "file_3047 = '/content/drive/MyDrive/Colab Notebooks/Exercise 2/IMG_3047.CR3'\n",
        "file_3048 = '/content/drive/MyDrive/Colab Notebooks/Exercise 2/IMG_3048.CR3'\n",
        "file_3049 = '/content/drive/MyDrive/Colab Notebooks/Exercise 2/IMG_3049.CR3'\n",
        "# Load the images using rawpy\n",
        "with rawpy.imread(file_3044) as raw:\n",
        "    img_3044 = raw.postprocess()\n",
        "with rawpy.imread(file_3045) as raw:\n",
        "    img_3045 = raw.postprocess()\n",
        "with rawpy.imread(file_3046) as raw:\n",
        "    img_3046 = raw.postprocess()\n",
        "with rawpy.imread(file_3047) as raw:\n",
        "    img_3047 = raw.postprocess()\n",
        "with rawpy.imread(file_3048) as raw:\n",
        "    img_3048 = raw.postprocess()\n",
        "with rawpy.imread(file_3049) as raw:\n",
        "    img_3049 = raw.postprocess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "1BlAlI5hgF68",
        "outputId": "9f8e1265-5446-4127-f9ef-b01f4a88d7db"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy arrays\n",
        "array_3044 = np.array(img_3044)\n",
        "array_3045 = np.array(img_3045)\n",
        "array_3046 = np.array(img_3046)\n",
        "array_3047 = np.array(img_3047)\n",
        "array_3048 = np.array(img_3048)\n",
        "array_3049 = np.array(img_3049)\n",
        "\n",
        "# Calculate the average values of red, green, and blue pixels for each image\n",
        "avg_3044 = np.mean(array_3044, axis=(0, 1))\n",
        "avg_3045 = np.mean(array_3045, axis=(0, 1))\n",
        "avg_3046 = np.mean(array_3046, axis=(0, 1))\n",
        "avg_3047 = np.mean(array_3047, axis=(0, 1))\n",
        "avg_3048 = np.mean(array_3048, axis=(0, 1))\n",
        "avg_3049 = np.mean(array_3049, axis=(0, 1))\n",
        "# Exposure times\n",
        "exposure_times = np.array([1/10, 1/20, 1/40, 1/80, 1/160, 1/320])\n",
        "\n",
        "# Plotting the averages against exposure times\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Red channel\n",
        "plt.plot(exposure_times,[avg_3044[0], avg_3045[0],avg_3046[0],avg_3047[0],avg_3048[0],avg_3049[0]], 'r-o', label='Red')\n",
        "\n",
        "# Green channel\n",
        "plt.plot(exposure_times,[avg_3044[1], avg_3045[1],avg_3046[1],avg_3047[1],avg_3048[1],avg_3049[1]], 'g-o', label='Green')\n",
        "\n",
        "# Blue channel\n",
        "plt.plot(exposure_times,[avg_3044[2], avg_3045[2],avg_3046[2],avg_3047[2],avg_3048[2],avg_3049[2]], 'b-o', label='Blue')\n",
        "\n",
        "plt.title('Average RGB Values vs. Exposure Time')\n",
        "plt.xlabel('Exposure Time (seconds)')\n",
        "plt.ylabel('Average Pixel Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4OZHHxvoM8u"
      },
      "source": [
        "# **Exercise Three**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B_wLthVzAyx"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from scipy.signal import convolve2d\n",
        "import rawpy\n",
        "import numpy as np\n",
        "def read_raw_image(file_path):\n",
        "    with rawpy.imread(file_path) as raw:\n",
        "        # Extract the raw data\n",
        "        raw_data = raw.raw_image_visible.copy()\n",
        "    return raw_data\n",
        "\n",
        "\n",
        "def create_color_masks(image_shape):\n",
        "    \"\"\"\n",
        "    Create masks for each color channel based on the Bayer pattern.\n",
        "    Assumes RGGB pattern by default.\n",
        "    \"\"\"\n",
        "    mask_r = np.zeros(image_shape, dtype=np.uint8)\n",
        "    mask_g = np.zeros(image_shape, dtype=np.uint8)\n",
        "    mask_b = np.zeros(image_shape, dtype=np.uint8)\n",
        "\n",
        "    for row in range(image_shape[0]):\n",
        "        for col in range(image_shape[1]):\n",
        "            if (row % 2 == 0) and (col % 2 == 0):\n",
        "                mask_r[row, col] = 1\n",
        "            elif (row % 2 == 1) and (col % 2 == 1):\n",
        "                mask_b[row, col] = 1\n",
        "            else:\n",
        "                mask_g[row, col] = 1\n",
        "            print(mask_r)\n",
        "            print(mask_g)\n",
        "            print(mask_b)\n",
        "\n",
        "    return mask_r, mask_g, mask_b\n",
        "\n",
        "\n",
        "def convert_to_8bit(image, bit_depth=14):\n",
        "    return (image / (2**bit_depth - 1)) * 255\n",
        "\n",
        "\n",
        "def demosaic(raw_image):\n",
        "    \"\"\"\n",
        "    Demosaic the image using the given masks and convolution kernel.\n",
        "    \"\"\"\n",
        "    # Create masks for the RGGB Bayer pattern\n",
        "    r_mask, g_mask, b_mask = create_color_masks(raw_image.shape)\n",
        "\n",
        "    # Define the demosaicing kernel (you can use a different kernel if needed)\n",
        "    demosaic_kernel = np.array([[1.0, 1.0, 1.0],\n",
        "                                [1.0, 1.0, 1.0],\n",
        "                                [1.0, 1.0, 1.0]])\n",
        "\n",
        "    r = convolve2d(raw_image * r_mask, demosaic_kernel, mode='same', boundary='symm')\n",
        "    g = convolve2d(raw_image * g_mask, demosaic_kernel, mode='same', boundary='symm')\n",
        "    b = convolve2d(raw_image * b_mask, demosaic_kernel, mode='same', boundary='symm')\n",
        "\n",
        "    # Normalize\n",
        "    r /= convolve2d(r_mask, demosaic_kernel, mode='same', boundary='symm')\n",
        "    g /= convolve2d(g_mask, demosaic_kernel, mode='same', boundary='symm')\n",
        "    b /= convolve2d(b_mask, demosaic_kernel, mode='same', boundary='symm')\n",
        "\n",
        "    # Convert the demosaiced channels to 8-bit depth\n",
        "    r_channel_8bit = convert_to_8bit(r)\n",
        "    g_channel_8bit = convert_to_8bit(g)\n",
        "    b_channel_8bit = convert_to_8bit(b)\n",
        "\n",
        "    color_image = np.dstack((r_channel_8bit, g_channel_8bit, b_channel_8bit)).astype(np.uint8)\n",
        "\n",
        "    return color_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "1ExJqILGzHU1",
        "outputId": "10f88a13-5b44-4650-9868-3b9185c45eb8"
      },
      "outputs": [],
      "source": [
        "raw_image = read_raw_image(\"exercise_2_data/03/IMG_4782.CR3\")\n",
        "color_image = demosaic(raw_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGsAy2jnHSOt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Display the resulting color image\n",
        "plt.imshow(color_image)\n",
        "plt.title(\"Demosaiced Color Image\")\n",
        "plt.axis('off')  # Turn off axis labels and ticks\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGoB4t1mHt9W"
      },
      "outputs": [],
      "source": [
        "# Convert the resulting color_image to YUV color space\n",
        "yuv_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2YUV)\n",
        "\n",
        "# Apply median filtering to U and V channels\n",
        "median_filtered_u = cv2.medianBlur(yuv_image[:, :, 1], ksize=5)  # Adjust kernel size as needed\n",
        "median_filtered_v = cv2.medianBlur(yuv_image[:, :, 2], ksize=5)  # Adjust kernel size as needed\n",
        "\n",
        "# Create a new YUV image with the filtered U and V channels\n",
        "filtered_yuv_image = np.stack((yuv_image[:, :, 0], median_filtered_u, median_filtered_v), axis=-1)\n",
        "\n",
        "# Convert the filtered YUV image back to RGB\n",
        "filtered_rgb_image = cv2.cvtColor(filtered_yuv_image, cv2.COLOR_YUV2RGB)\n",
        "\n",
        "# Display the resulting filtered color image\n",
        "plt.imshow(filtered_rgb_image)\n",
        "plt.title(\"Filtered Color Image\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAhSZSFFIARv"
      },
      "source": [
        "# **Exercise Four**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YC7rXspWOkds"
      },
      "outputs": [],
      "source": [
        "filtered_rgb_image.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKw8Kzh-OQ31"
      },
      "outputs": [],
      "source": [
        "# Normalize using percentiles first\n",
        "a = np.percentile(filtered_rgb_image, 0.01)\n",
        "b = np.percentile(filtered_rgb_image, 99.99)\n",
        "normalized_image = (filtered_rgb_image - a) / (b - a)\n",
        "normalized_image[normalized_image < 0] = 0\n",
        "normalized_image[normalized_image > 1] = 1\n",
        "\n",
        "gamma = 0.3\n",
        "# Apply gamma correction on the normalized image\n",
        "gamma_corrected_image = normalized_image ** gamma\n",
        "\n",
        "# Convert to 8-bit type for display, scale up to the 8-bit range\n",
        "gamma_corrected_image = 255 * gamma_corrected_image\n",
        "gamma_corrected_image[gamma_corrected_image < 0] = 0\n",
        "gamma_corrected_image[gamma_corrected_image > 255] = 255\n",
        "gamma_corrected_image = gamma_corrected_image.astype(np.uint8)\n",
        "\n",
        "# Display the gamma corrected image\n",
        "plt.imshow(gamma_corrected_image)\n",
        "plt.title(\"Gamma Corrected Image\")\n",
        "plt.axis('off') # Hide the axes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCMZ9dv9QEni"
      },
      "source": [
        "# **Exercise Five**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vktFWobpQGpG"
      },
      "outputs": [],
      "source": [
        "def white_balance(gamma_corrected_image):\n",
        "\n",
        "  mi = np.mean(gamma_corrected_image)\n",
        "\n",
        "  # Apply white balance to each channel by multiplying them by mi / mc\n",
        "  white_balanced_image = np.zeros_like(gamma_corrected_image, dtype=np.float64)\n",
        "  for channel in range(3):  # Iterate over RGB channels\n",
        "      mc = np.mean(gamma_corrected_image[:, :, channel])\n",
        "      white_balanced_image[:, :, channel] = gamma_corrected_image[:, :, channel] * (mi / mc)\n",
        "\n",
        "  # Clip values to a maximum of 255\n",
        "  white_balanced_image[white_balanced_image > 255] = 255\n",
        "\n",
        "  # Convert to uint8 type for display\n",
        "  white_balanced_image = white_balanced_image.astype(np.uint8)\n",
        "\n",
        "  return white_balanced_image\n",
        "\n",
        "white_balanced_image = white_balance(gamma_corrected_image)\n",
        "\n",
        "# Display the white balanced image\n",
        "plt.imshow(white_balanced_image)\n",
        "plt.title(\"White Balanced Image (Gray World)\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxjsmKBsPgWm"
      },
      "outputs": [],
      "source": [
        "# Create a figure with 1 row and 3 columns for the three images\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot the filtered_rgb_image on the left\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(filtered_rgb_image)\n",
        "plt.title(\"Filtered Color Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot the gamma_corrected_image in the middle\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(gamma_corrected_image)\n",
        "plt.title(\"Gamma Corrected and Normalized Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot the white_balanced_image on the right\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(white_balanced_image)\n",
        "plt.title(\"White Balanced Image (Gray World)\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()  # Optional for better layout\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WIjkmo_cGKt"
      },
      "source": [
        "# ****PART 2****\n",
        "# Exercise Six"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Syp4NZXYsfOC"
      },
      "outputs": [],
      "source": [
        "def simple_hdr_combination(images, exposure_times):\n",
        "    # Assume the longest exposure is the base (h)\n",
        "    h = images[0] / exposure_times[0]\n",
        "    for i, img in enumerate(images[1:]):\n",
        "        # Multiply by the relative exposure time difference\n",
        "        exp_diff = exposure_times[i-1] - exposure_times[i]\n",
        "        img_exp_diff = img * exp_diff\n",
        "        # Replace values in h with values from img_scaled where img_scaled is greater\n",
        "        threshold = 0.8 * h.max()\n",
        "        h = np.where(img_exp_diff > threshold, img_exp_diff, h)\n",
        "    return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfaESq6vtnrV"
      },
      "outputs": [],
      "source": [
        "def gamma_correction(image, gamma):\n",
        "    # Apply gamma correction\n",
        "    return np.power(image, gamma)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ePz66zu-uRj"
      },
      "outputs": [],
      "source": [
        "def weighted_hdr_combination(images, exposure_times):\n",
        "    # Calculate the weights for each image\n",
        "    weights = [1.0 / t for t in exposure_times]\n",
        "\n",
        "    # Normalize images based on exposure time and apply weights\n",
        "    normalized_images = [img * w for img, w in zip(images, weights)]\n",
        "\n",
        "    # Initialize HDR image with zeros\n",
        "    hdr_image = np.zeros_like(normalized_images[0])\n",
        "\n",
        "    # Calculate the weighted sum of normalized images\n",
        "    for norm_img in normalized_images:\n",
        "        hdr_image += norm_img\n",
        "\n",
        "    # Normalize the HDR image to bring the pixel values between 0 and 1\n",
        "    hdr_image /= np.sum(weights)\n",
        "        # Apply tone mapping\n",
        "    tone_mapped_image = np.log(1 + hdr_image) / np.log(2)  # Logarithmic tone mapping\n",
        "\n",
        "    # Normalize the tone-mapped image to bring the pixel values between 0 and 1\n",
        "    tone_mapped_image /= np.max(tone_mapped_image)\n",
        "    gamma_corrected_image = gamma_correction(tone_mapped_image, gamma=0.03)\n",
        "    # Apply white balance\n",
        "    final_image = white_balance(gamma_corrected_image)\n",
        "\n",
        "    return final_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtL-iibXshC9"
      },
      "outputs": [],
      "source": [
        "file_paths = ['/content/drive/MyDrive/Colab Notebooks/Exercise 6/00.CR3', '/content/drive/MyDrive/Colab Notebooks/Exercise 6/01.CR3', '/content/drive/MyDrive/Colab Notebooks/Exercise 6/02.CR3',\n",
        "              '/content/drive/MyDrive/Colab Notebooks/Exercise 6/03.CR3', '/content/drive/MyDrive/Colab Notebooks/Exercise 6/04.CR3', '/content/drive/MyDrive/Colab Notebooks/Exercise 6/05.CR3',\n",
        "              '/content/drive/MyDrive/Colab Notebooks/Exercise 6/06.CR3', '/content/drive/MyDrive/Colab Notebooks/Exercise 6/07.CR3', '/content/drive/MyDrive/Colab Notebooks/Exercise 6/08.CR3',\n",
        "              '/content/drive/MyDrive/Colab Notebooks/Exercise 6/09.CR3', '/content/drive/MyDrive/Colab Notebooks/Exercise 6/10.CR3']\n",
        "\n",
        "exposure_times = [1, 1/2, 1/4, 1/8, 1/16, 1/32, 1/64, 1/128, 1/256, 1/512, 1/1024, 1/2048]\n",
        "\n",
        "# Read and process images\n",
        "images = [read_raw_image(file_path) for file_path in file_paths]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef27OkT-wVLD"
      },
      "outputs": [],
      "source": [
        "images[10].ah"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q2tZCD_HYhQ"
      },
      "outputs": [],
      "source": [
        "# Merge to HDR\n",
        "hdr_image = weighted_hdr_combination(images, exposure_times)\n",
        "\n",
        "print(hdr_image.dtype)\n",
        "print(hdr_image.max())\n",
        "plt.imshow(hdr_image, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huoHHeiEqgRL"
      },
      "outputs": [],
      "source": [
        "hdr_image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMw33MY7snLh"
      },
      "outputs": [],
      "source": [
        "white_balanced_image = white_balance(hdr_image)\n",
        "print(white_balanced_image.dtype)\n",
        "print(white_balanced_image.shape)\n",
        "print(white_balanced_image.max())\n",
        "plt.imshow(white_balanced_image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVlPs9KBsot0"
      },
      "outputs": [],
      "source": [
        "def reduce_dynamic_range(image):\n",
        "    # Apply logarithmic compression\n",
        "    image_log = np.log1p(image)\n",
        "    # Scale to [0, 255]\n",
        "    image_norm = (image_log - image_log.min()) / (image_log.max() - image_log.min())\n",
        "    image_8bit = (image_norm * 255).astype(np.uint8)\n",
        "    return image_8bit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ6MtpxHsqxr"
      },
      "outputs": [],
      "source": [
        "final_image = reduce_dynamic_range(hdr_image)\n",
        "print(final_image.dtype)\n",
        "print(final_image.shape)\n",
        "print(final_image.max())\n",
        "plt.imshow(final_image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeCMpfr4slVK"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import convolve2d\n",
        "demosaiced_image = demosaic(final_image)\n",
        "print(demosaiced_image.dtype)\n",
        "print(demosaiced_image.shape)\n",
        "print(demosaiced_image.max())\n",
        "plt.imshow(demosaiced_image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zekEyQP5ssss"
      },
      "outputs": [],
      "source": [
        "# Save the image\n",
        "imageio.imwrite('hdr_image.png', final_image)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aL1J9WqtfSlm",
        "ZESEPl9YgBoc",
        "x4OZHHxvoM8u",
        "gAhSZSFFIARv"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
